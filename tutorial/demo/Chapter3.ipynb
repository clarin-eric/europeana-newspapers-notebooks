{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ef29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae044b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (5.4.0)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.10/site-packages (from nbformat) (4.10.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat) (4.6.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat) (2.15.3)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/conda/lib/python3.10/site-packages (from nbformat) (5.2.2.post1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28157ae-a393-4406-8381-c9c1921ca2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Utilities\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "from io import BytesIO\n",
    "import json\n",
    "import logging\n",
    "from lxml import etree\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\"\"\"\n",
    "    Globals\n",
    "\"\"\"\n",
    "\n",
    " # Poland\n",
    "set_id = '9200357'\n",
    "\n",
    "data_dir = f'{os.path.expanduser(\"~\")}/data'\n",
    "metadata_dir = f'{os.path.expanduser(\"~\")}/work/temp/metadata/{set_id}'\n",
    "nsmap = {\"cmd\": \"http://www.clarin.eu/cmd/1\",\n",
    "         \"cmdp_text\": \"http://www.clarin.eu/cmd/1/profiles/clarin.eu:cr1:p_1633000337997\"}\n",
    "output_file = f'{os.path.expanduser(\"~\")}/output'\n",
    "\n",
    "\n",
    "# with open(f'{data_dir}/{set_id}/id_file_map.json', 'r') as id_filename_map_file:\n",
    "#     id_filename_map = json.load(id_filename_map_file)\n",
    "\n",
    "YYYY_MM_DD = re.compile(r\"(?P<year>[0-9]{4})-(?P<month>[0-9]{1,2})-(?P<day>[0-9]{1,2})\")\n",
    "MAX_NER_TASK_SIZE = 2000000\n",
    "\n",
    "\"\"\"\n",
    "    Metadata printing\n",
    "\"\"\"\n",
    "def print_xml(tree, declaration: bool = False):\n",
    "    print(etree.tostring(tree, encoding='UTF-8', xml_declaration=declaration, pretty_print=True).decode())\n",
    "\n",
    "\"\"\"\n",
    "    Data acess\n",
    "\"\"\"\n",
    "def get_resource_file(identifier):\n",
    "    \"\"\"\n",
    "        Resolves Europeana subresource identifier to it's local location. \n",
    "        \n",
    "        :param str identifier: Europeana subresource identifier\n",
    "        :return str: Path to local location of the resource\n",
    "    \"\"\"\n",
    "    if identifier in id_filename_map:\n",
    "        filename = id_filename_map[identifier]\n",
    "        return f'{data_dir}/{set_id}/{filename}'\n",
    "\n",
    "def get_date_from_metadata(metadata_tree):\n",
    "    dates = metadata_tree.xpath(\"///cmdp_text:TemporalCoverage/cmdp_text:Start/cmdp_text:date/text()\", namespaces=nsmap)\n",
    "    dates = [YYYY_MM_DD.match(date) for date in dates]\n",
    "    dates = [datetime.date(int(date.group(\"year\")), int(date.group(\"month\")), int(date.group(\"day\"))) for date in dates]\n",
    "    return dates\n",
    "    \n",
    "def get_description_from_metadata(metadata_tree):\n",
    "    descriptions = metadata_tree.xpath('//cmdp_text:TextResource/cmdp_text:Description/cmdp_text:description/text()', namespaces=nsmap)\n",
    "    if len(descriptions) > 0:\n",
    "        return descriptions[0]\n",
    "    \n",
    "def get_resource_ids_from_metadata(metadata_tree):\n",
    "    ids = metadata_tree.xpath('//cmdp_text:SubresourceDescription/cmdp_text:IdentificationInfo/cmdp_text:identifier/text()', namespaces=nsmap)\n",
    "    # The result can be any number of identifiers. We do want to filter the values a bit: only the numeric identifiers are useful \n",
    "    # to us so we use the special syntax below to make a new list by picking only the matching values from the query results list\n",
    "    return [id for id in ids if id.isnumeric()]\n",
    "\n",
    "def get_title_from_metadata(metadata_tree):\n",
    "    # Get all the values from the xpath\n",
    "    titles = metadata_tree.xpath('//cmdp_text:TextResource/cmdp_text:TitleInfo/cmdp_text:title/text()', namespaces=nsmap)\n",
    "    # Check if there is an actual value\n",
    "    if len(titles) > 0:\n",
    "        # Return the first (assuming only) value\n",
    "        return titles[0]\n",
    "\n",
    "def unpack_metadata(set_id, target_dir):\n",
    "    # Construct the address of the .zip file with the metadata for one set\n",
    "    md_zip_url = f'https://europeana-oai.clarin.eu/metadata/fulltext-aggregation/{set_id}.zip'\n",
    "    \n",
    "    # Retrieve the .zip file\n",
    "    print(f'Retrieving {md_zip_url}')\n",
    "    resp = requests.get(md_zip_url)\n",
    "    zipfile = ZipFile(BytesIO(resp.content))\n",
    "    \n",
    "    # Uncompress the .zip into the target directory\n",
    "    print(f'Extracting content in {target_dir}')\n",
    "    zipfile.extractall(path=target_dir)\n",
    "    print('Done')\n",
    "\n",
    "\"\"\"\n",
    "    Zip/Unzip\n",
    "\"\"\"\n",
    "def zip_file(input_path, output_path=\"\"):\n",
    "    \"\"\"\n",
    "        Zips input file/directory\n",
    "        \n",
    "        :param str input_path: path to file to be zipped, if file is directory, entire dir gets zipped\n",
    "        :param str output_path: path to location, where to save the archive. If empty, zip archive uses same location and name as input\n",
    "        :returns str: path to archive\n",
    "    \"\"\"\n",
    "    if not output_path:\n",
    "        output_path = f\"{os.path.dirname(input_path)}/{os.path.basename(input_path).split('.')[0]}.zip\"\n",
    "    with ZipFile(output_path, 'r') as zip_handle:\n",
    "        logger.info(f'Zipping {input_path} to {output_path}')\n",
    "        if os.path.isdir(input_path):\n",
    "            _zip_dir(input_path, zip_handle)\n",
    "        else:\n",
    "            zip_handle.write(input_path, os.path.basename(input_path))\n",
    "            # _zip_chunker(input_path)\n",
    "        \n",
    "    return output_path\n",
    "        \n",
    "def unzip_file(input_path, output_path=\"\"):\n",
    "    \"\"\"\n",
    "        Unzips input .zip file\n",
    "        \n",
    "        :param str input_path: path to file to be unzipped\n",
    "        :param str output_path: path to location, where to unpack the archive. If empty, archive is extracted at its location.\n",
    "    \"\"\"\n",
    "    if not output_path:\n",
    "        output_path = f\"{os.path.dirname(input_path)}/{os.path.basename(input_path).split('.')[0]}\"\n",
    "        print(\"$$\")\n",
    "        print(output_path)\n",
    "        print(input_path)\n",
    "    with ZipFile(input_path, 'r') as zip_ref:\n",
    "        logger.info(f'Unzipping {input_path} to {output_path}')\n",
    "        zip_ref.extractall()\n",
    "        extracted_files_paths = zip_ref.namelist()\n",
    "        \n",
    "    return [os.path.join(output_path, extracted_file_path) for extracted_file_path in extracted_files_paths]\n",
    "\n",
    "def _zip_dir(input_dir_path, zip_handle):\n",
    "    for dirname, subdirs, files in os.walk(input_dir_path):\n",
    "        for filename in files:          \n",
    "            logger.info(f'Zipping {dirname}/{filename}')\n",
    "            # _zip_chunker(os.path.join(dirname, filename))\n",
    "            zip_handle.write(os.path.join(dirname, filename), \n",
    "                             os.path.relpath(os.path.join(dirname, filename), \n",
    "                                             os.path.join(input_dir_path, '..')))\n",
    "            \n",
    "\"\"\"\n",
    "    Safety\n",
    "\"\"\"\n",
    "def _check_task_size(resources):\n",
    "    size = sum([os.path.getsize(resource) for resource in resources])\n",
    "    if size > MAX_NER_TASK_SIZE:\n",
    "        raise TaskTooBigError\n",
    "        \n",
    "class TaskTooBigError(Exception):\n",
    "    \"\"\"\n",
    "        Exception raised for tasks with too big payload.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, max_size):\n",
    "        self.message = f\"Task's payload is too big, it has {size} and maximum is {max_size}\"\n",
    "        super().__init__(self.message)\n",
    "   \n",
    "\"\"\"\n",
    "    Logging\n",
    "\"\"\"\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bc8c8-0b55-4b1c-b666-3a86ec07e670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb3025-4aa3-42fe-b8bc-7bf3f33f9cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc76fdd3-6489-4f92-b590-b2e322e88683",
   "metadata": {},
   "source": [
    "## Named Entity Recognition with Liner2\n",
    "\n",
    "In this section we will present how to use Europeana bibliographic resources with Named Entity Recognition (NER) tool for Polish using [lpmn_client](https://wiki.clarin-pl.eu/en/nlpws/lpmn_client) and [Liner2](https://github.com/CLARIN-PL/Liner2). Due to the server side limitation, we ensure 2M limit on size on the task with function defined below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c493718-6d21-475f-9886-54ce36ef31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.clarin-pl.eu\n",
      "Collecting lpmn_client\n",
      "  Downloading http://pypi.clarin-pl.eu/packages/lpmn_client-1.4.6-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (2.27.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2.0.12)\n",
      "Installing collected packages: lpmn_client\n",
      "Successfully installed lpmn_client-1.4.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Install lpmn client and import it\n",
    "\"\"\"\n",
    "!pip install -i https://pypi.clarin-pl.eu lpmn_client\n",
    "\n",
    "\n",
    "from lpmn_client import download_file, upload_file\n",
    "from lpmn_client import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25477234-dba1-4c90-86b5-d2bcf2cea200",
   "metadata": {},
   "source": [
    "### Spellchecking with lpmn client\n",
    "\n",
    "OCR output tends to contains spelling mistakes that adds noise to the data. Below we show how to use lpmn clinet to specify task pipeline in order to obtain spell-checked textual data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2d936-f059-411e-bcc5-4122a9cdaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function for tasking lpmn client with Liner2 NER pipeline with task size control \n",
    "\"\"\"\n",
    "\n",
    "def lpmn_client_task(resources, task, names=[]):\n",
    "    \"\"\"\n",
    "        Wrap over CLARIN-PL lpmn client with control of the task size in order to avoid jamming the task queue on the server side\n",
    "        \n",
    "        :param list resources: list of paths to the resources to be processed\n",
    "        :param list names: optional list of names for output files, has to be same length as resources\n",
    "        :returns list: list of paths to the output zip files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Size check\n",
    "    _check_task_size(resources)\n",
    "    # Upload reasources to task queue\n",
    "    job_ids = [upload_file(resource_file) for resource_file in resources]\n",
    "    # Specify pipeline \n",
    "    t = Task(task)\n",
    "    # Run uploaded tasks with pipeline\n",
    "    output_file_ids = [t.run(job_id, verbose=True) for job_id in job_ids]\n",
    "    if names:\n",
    "        output = [download_file(output_file_id, output_file, filename) \n",
    "                         for output_file_id, filename in zip(output_file_ids, names)]\n",
    "    else:\n",
    "        output = [download_file(output_file_id, output_file, os.path.basename(resource)) \n",
    "                         for output_file_id, resource in zip(output_file_ids, resources)]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaf0eb0-9333-480f-9f08-985e16ced020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://europeana-oai.clarin.eu/metadata/fulltext-aggregation/9200357.zip\n",
      "Extracting content in /home/jovyan/work/temp/metadata/9200357\n",
      "Done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'id_filename_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m id_date_first_issue_january \u001b[38;5;241m=\u001b[39m [(_id, date) \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m ids_dates_january \u001b[38;5;28;01mfor\u001b[39;00m _ids, date \u001b[38;5;129;01min\u001b[39;00m year \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m first_issues_date_per_year]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Map id to reasource\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m resources_dates \u001b[38;5;241m=\u001b[39m [(get_resource_file(_id), date) \u001b[38;5;28;01mfor\u001b[39;00m _id, date \u001b[38;5;129;01min\u001b[39;00m id_date_first_issue_january]\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m id_date_first_issue_january \u001b[38;5;241m=\u001b[39m [(_id, date) \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m ids_dates_january \u001b[38;5;28;01mfor\u001b[39;00m _ids, date \u001b[38;5;129;01min\u001b[39;00m year \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m first_issues_date_per_year]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Map id to reasource\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m resources_dates \u001b[38;5;241m=\u001b[39m [(\u001b[43mget_resource_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m, date) \u001b[38;5;28;01mfor\u001b[39;00m _id, date \u001b[38;5;129;01min\u001b[39;00m id_date_first_issue_january]\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mget_resource_file\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_resource_file\u001b[39m(identifier):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m        Resolves Europeana subresource identifier to it's local location. \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m        :param str identifier: Europeana subresource identifier\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m        :return str: Path to local location of the resource\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m identifier \u001b[38;5;129;01min\u001b[39;00m \u001b[43mid_filename_map\u001b[49m:\n\u001b[1;32m     51\u001b[0m         filename \u001b[38;5;241m=\u001b[39m id_filename_map[identifier]\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id_filename_map' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Let's select resources. We will use Izraelita newspapers from 1910-1913 to investigate most frequent Named Entities over the years on January. \n",
    "\"\"\"\n",
    "\n",
    "# Prepare metadata of the collection\n",
    "unpack_metadata(set_id, metadata_dir)\n",
    "izraelita_metadata_files = [f\"{metadata_dir}/Izraelita_1910.xml\",\n",
    "                            f\"{metadata_dir}/Izraelita_1911.xml\",\n",
    "                            f\"{metadata_dir}/Izraelita_1912.xml\",\n",
    "                            f\"{metadata_dir}/Izraelita_1913.xml\",\n",
    "                           ]\n",
    "\n",
    "# Use getters to obtain date and id from metadata\n",
    "izraelita_metadata_trees = [etree.parse(izraelita_metadata_file) for izraelita_metadata_file in izraelita_metadata_files]\n",
    "ids = [get_resource_ids_from_metadata(izraelita_metadata_tree) for izraelita_metadata_tree in izraelita_metadata_trees]\n",
    "dates = [get_date_from_metadata(izraelita_metadata_tree) for izraelita_metadata_tree in izraelita_metadata_trees]\n",
    "\n",
    "# Get all issues from January\n",
    "ids_dates_january = []\n",
    "for _ids, _dates in zip (ids, dates):\n",
    "    year = []\n",
    "    for _id, date in zip(_ids, _dates):\n",
    "        if date.month==1:\n",
    "            year.append((_id, date))\n",
    "    ids_dates_january.append(year)\n",
    "\n",
    "# Get dates of first issues per year\n",
    "first_issues_date_per_year = {min([date for _, date in year]) for year in ids_dates_january}\n",
    "\n",
    "# Filter ids of first issues per year \n",
    "id_date_first_issue_january = [(_id, date) for year in ids_dates_january for _ids, date in year if date in first_issues_date_per_year]\n",
    "\n",
    "# Map id to reasource\n",
    "resources_dates = [(get_resource_file(_id), date) for _id, date in id_date_first_issue_january]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490613b-137f-4e44-9fef-db890016c12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3407fbc-f163-454d-89ea-697a218a9cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_check_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m    Let's spell check selected resources\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Safety check of the size of all resources meant for the task\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43m_check_size\u001b[49m(resources)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resource, date \u001b[38;5;129;01min\u001b[39;00m resources_dates:\n\u001b[1;32m      8\u001b[0m     lpmn_client_task([resource],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeller2\u001b[39m\u001b[38;5;124m\"\u001b[39m, [date])\n",
      "\u001b[0;31mNameError\u001b[0m: name '_check_size' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Let's spell check selected resources\n",
    "\"\"\"\n",
    "\n",
    "# Safety check of the size of all resources meant for the task\n",
    "_check_size(resources)\n",
    "for resource, date in resources_dates:\n",
    "    lpmn_client_task([resource],\"speller2\", [date])\n",
    "\n",
    "speller2_output_file_paths = [unzip_file(f\"{output_file}/{date}\") for _, date in resources_dates]\n",
    "print(speller2_output_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2bb3aef-e72e-4799-9f84-a5ce1491455e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_check_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Safety check of the size of all resources meant for the task\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43m_check_size\u001b[49m(resources)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resource, date \u001b[38;5;129;01min\u001b[39;00m resources_dates:\n\u001b[1;32m      4\u001b[0m     lpmn_client_task([resource],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124many2txt|wcrft2|liner2(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop9\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m})\u001b[39m\u001b[38;5;124m'\u001b[39m, [date])\n",
      "\u001b[0;31mNameError\u001b[0m: name '_check_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Safety check of the size of all resources meant for the task\n",
    "_check_size(resources)\n",
    "for resource, date in resources_dates:\n",
    "    lpmn_client_task([resource],'any2txt|wcrft2|liner2({\"model\":\"top9\"})', [date])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cad33a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resources_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresources_dates\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m liner2_output_file_paths \u001b[38;5;241m=\u001b[39m [unzip_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _, date \u001b[38;5;129;01min\u001b[39;00m resources_dates]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resources_dates' is not defined"
     ]
    }
   ],
   "source": [
    "for _, date in resources_dates:\n",
    "    print(f\"{output_file}/{date}\")\n",
    "liner2_output_file_paths = [unzip_file(f\"{output_file}/{date}\") for _, date in resources_dates]\n",
    "print(liner2_output_file_paths)\n",
    "# We flatten list [[file_path]] to [file_path]\n",
    "\n",
    "with open(liner2_output_file_paths[0], 'r') as liner2_output_file:\n",
    "    print(liner2_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dd0567-35b3-43e0-9eb1-68cf7938ef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nam', ['Azyi']), ('nam', ['Skan']), ('nam', ['Galacyi', 'w', 'Azyi', 'Mniejszej']), ('nam', ['Wiochom']), ('nam', ['Euro']), ('nam', ['Europy']), ('nam', ['Jońskiego']), ('nam', ['Europy']), ('nam', ['Turków']), ('nam', ['Europy']), ('nam', ['Południu']), ('nam', ['Fenicją']), ('nam', ['Europy']), ('nam', ['Fenicją']), ('nam', ['Azji', 'Mniejszej']), ('nam', ['Egiptu']), ('nam', ['Afryki']), ('nam', ['Europę', 'Azji']), ('nam', ['powstania', 'Bizan']), ('nam', ['Żydzi']), ('nam', ['Europy']), ('nam', ['Europy']), ('nam', ['Miletu']), ('nam', ['Bizancjum']), ('nam', ['Europy']), ('nam', ['Bagdadzie']), ('nam', ['Europa']), ('nam', ['Pale']), ('nam', ['Europy']), ('nam', ['Józef', '1Wasrrcug', 'W', 'przekroju']), ('nam', ['Jojkot']), ('nam', ['Austrję', 'Dolną']), ('nam', ['Galicję']), ('nam', ['Polaków']), ('nam', ['XIII']), ('nam', ['Aleksander']), ('nam', ['Polski']), ('nam', ['Dmowskiego']), ('nam', ['Graba']), ('nam', ['Graba']), ('nam', ['Janson']), ('nam', ['Miejskiego']), ('nam', ['Warszawie']), ('nam', ['Europie']), ('nam', ['Portugalii']), ('nam', ['Europy']), ('nam', ['Europy']), ('nam', ['Kraterze', 'p', '.', 'Ilesse', '-', 'War']), ('nam', ['Talmudu']), ('nam', ['Starzec']), ('nam', ['Ryfie']), ('nam', ['Dżerba']), ('nam', ['Dżebel', 'Ghariada', 'dachem']), ('nam', ['XI']), ('nam', ['Arabami']), ('nam', ['Berberom']), ('nam', ['Zachodu']), ('nam', ['Berberów']), ('nam', ['Francuzów']), ('nam', ['XX']), ('nam', ['St']), ('nam', ['Stanach']), ('nam', ['Columbia', 'Hat', 'Comp']), ('nam', ['Włoskie']), ('nam', ['H', '.', 'SIEOELBERG', 'i', 'S', '-', 'ka']), ('nam', ['URSUS', '\"', '—', 'Warszawa']), ('nam', ['Warszawa', '-', 'Sienna']), ('nam', ['I', '.', 'Cylkowa', 'Księga', 'Samuela']), ('nam', ['Jezajasza']), ('nam', ['Proroków']), ('nam', ['Pięciu', 'Mogiloth']), ('nam', ['Psalmy', 'Dawida']), ('nam', ['Przypowieści', 'Salomona']), ('nam', ['Marszałkowska', 'Nq', '135']), ('nam', ['Stanisław']), ('nam', ['Freudensohna']), ('nam', ['Warszawa']), ('nam', ['Stalowa', '7']), ('nam', ['Sz']), ('nam', ['Orlej', 'Nb', '3']), ('nam', ['Kamizelki']), ('nam', ['Chustki']), ('nam', ['Józef', 'Wasercug']), ('nam', ['Zielna', '20', 'Wydawczyni', 'Salomea', 'Peltynowa']), ('nam', ['Anglika']), ('nam', ['J']), ('nam', ['Ar']), ('nam', ['Argentyny']), ('nam', ['Karmel']), ('nam', ['Neui', '-', 'Yorku']), ('nam', ['Z', 'Cesarstwa']), ('nam', ['Senatu']), ('nam', ['Rosji']), ('nam', ['Tur']), ('nam', ['Turkestanu']), ('nam', ['Petersburgu']), ('nam', ['Rada', 'Ministrów']), ('nam', ['Warszawie']), ('nam', ['S', 'pełnienia', 'służby', 'wojskowej']), ('nam', ['Najwyższego']), ('nam', ['Petersburga']), ('nam', ['Sprostowanie']), ('nam', ['Izraelity']), ('nam', ['Paryż']), ('nam', ['Paryża']), ('nam', ['Widok']), ('nam', ['Bracha', 'Ho']), ('nam', ['BIURO', 'INSTflLIlCYlllO']), ('nam', ['Paryskie']), ('nam', ['Rysiej', 'Nq', '5']), ('nam', ['Kotwanda']), ('nam', ['Izraelity']), ('nam', ['Okryć', 'Damskich']), ('nam', ['Paryża']), ('nam', ['V', 'V']), ('nam', ['Pola']), ('nam', ['Polski']), ('nam', ['Zjednoczenie', 'Postępowe']), ('nam', ['P', '.', 'Z', '.', 'P']), ('nam', ['Jagiełły']), ('nam', ['Cesarstwa']), ('nam', ['Dmowskiego']), ('nam', ['Jagiełły']), ('nam', ['Jagiełły']), ('nam', ['Jagiełły']), ('nam', ['Rady', 'mini']), ('nam', ['Dumie']), ('nam', ['Anny']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Aniu']), ('nam', ['ANNA']), ('nam', ['Aniu']), ('nam', ['ANNA']), ('nam', ['Grabę']), ('nam', ['Graba']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Darskieao']), ('nam', ['Graba']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Jagiełły']), ('nam', ['Frajnda']), ('nam', ['Najes', 'Lodzer', 'MorgenblattJ']), ('nam', ['Prasa', 'żydowska']), ('nam', ['Izraelita']), ('nam', ['Izraelitów']), ('nam', ['Rumunja']), ('nam', ['Red']), ('nam', ['Karolu']), ('nam', ['ANNA']), ('nam', ['Aniu']), ('nam', ['Darskiego']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Darskiego']), ('nam', ['ANNA']), ('nam', ['Karolu']), ('nam', ['ANNA']), ('nam', ['G', 'BUDZYNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Aniu']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['C', '.', 'd']), ('nam', ['Nalewki']), ('nam', ['Kurnatowski']), ('nam', ['Kraków']), ('nam', ['Polaków']), ('nam', ['Polaków']), ('nam', ['Niemców']), ('nam', ['Izraeli']), ('nam', ['ZŁODZIEJE']), ('nam', ['Andrzeja', 'Marka']), ('nam', ['Aniu']), ('nam', ['ANNA']), ('nam', ['Jaki']), ('nam', ['ANNA']), ('nam', ['Graba']), ('nam', ['Aniu']), ('nam', ['ANNA']), ('nam', ['Karolu']), ('nam', ['ANNA']), ('nam', ['ANNA']), ('nam', ['Karola']), ('nam', ['Durskiego']), ('nam', ['Karol']), ('nam', ['Barskiego']), ('nam', ['St', ',', 'Zjednoczonych']), ('nam', ['Jat', '14']), ('nam', ['I', '.', 'C', '.', 'A']), ('nam', ['Sta', 'nach', 'Zjednoczonych']), ('nam', ['Dane']), ('nam', ['Służba']), ('nam', ['Rolnicy']), ('nam', ['I', '.', 'C', '.', 'A']), ('nam', ['Stan']), ('nam', ['Argentyny']), ('nam', ['Stanów', 'Zjednoczonych']), ('nam', ['Baltimora']), ('nam', ['Ńew', '-', 'Jorku']), ('nam', ['Kanada']), ('nam', ['Palestyna']), ('nam', ['Paryżu']), ('nam', ['Paryżu']), ('nam', ['Tur']), ('nam', ['Złotników']), ('nam', ['Pracowników']), ('nam', ['Pracowników']), ('nam', ['Instalatorów', '2', ',', '500', 'S', 'korników']), ('nam', ['Mechaników']), ('nam', ['Rzeźników', '12', 'Czapników']), ('nam', ['Kuśnierzy']), ('nam', ['Szewców']), ('nam', ['Argentyny']), ('nam', ['Argentyna']), ('nam', ['Argentyny']), ('nam', ['Warszawie']), ('nam', ['Warszawie']), ('nam', ['ADMINISTRACJA', 'No', 'wy', '-', 'Świat', 'Na', '36']), ('nam', ['OGŁOSZENIA']), ('nam', ['Nekrologi']), ('nam', ['Józefa', 'Wasercuga']), ('nam', ['Jagiełły']), ('nam', ['Z', 'Cesarstwa']), ('nam', ['Andrzeja', 'Marka']), ('nam', ['Długa', 'No']), ('nam', ['Patery']), ('nam', ['Szpitalna']), ('nam', ['Al']), ('nam', ['Izraelity']), ('nam', ['Broń', 'Bo', 'że']), ('nam', ['Kurnatowski']), ('nam', ['Polaków']), ('nam', ['Polaków']), ('nam', ['Polaków']), ('nam', ['Smirnicl']), ('nam', ['tel', '.', '37', '-', '52', '.', 'PETERSBURG', '—', 'ŁÓDŹ']), ('nam', ['PRZEPROWADZKI', 'MEBLI', 'KRAKÓW']), ('nam', ['TSYRENA', 'Aby'])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Function for extracting annotations from Liner2 xml output\n",
    "\"\"\"\n",
    "\n",
    "test_path = f'{output_file}/1911-01-01.txt'\n",
    "\n",
    "def liner2_xml_to_annotation(path_to_xml):\n",
    "    \"\"\"\n",
    "        Converts xml doc into list of annotations and tokens\n",
    "        \n",
    "        :param str path_to_xml: path to .xml Liner2 output file\n",
    "        :returns list: list of tuples (annotation_type, [tokens])\n",
    "    \"\"\"\n",
    "    with open(path_to_xml, \"r\") as xml_file:\n",
    "        xml_tree = etree.parse(path_to_xml)\n",
    "        sentences = xml_tree.xpath(\"//sentence\")\n",
    "        annotated_tokens = [sentence.xpath(\"./tok[./ann!=0]\") for sentence in sentences]\n",
    "        # Prune empty lists\n",
    "        annotated_tokens = filter(lambda x: True if x else False, annotated_tokens)\n",
    "        annotated_tokens = [_chain_annotations(sentence) for sentence in annotated_tokens]\n",
    "        return annotated_tokens\n",
    "        \n",
    "def _chain_annotations(sentence: list):\n",
    "    annotation_heads = [token.xpath(\"./ann[@head]\") for token in sentence]\n",
    "    for token in annotation_heads:\n",
    "        for annotation_head in token:\n",
    "            annotation_channel = annotation_head.xpath(\"./text()\")[0]\n",
    "            annotation_type = annotation_head.get(\"chan\")\n",
    "            annotation_tokens = [token.xpath(\"./orth/text()\")[0] for token in sentence if token.xpath(f\"./ann[text()={annotation_channel}]\")]\n",
    "    return annotation_type, annotation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c6a523-8077-4442-b1bd-be4bfb80ac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nam'}\n"
     ]
    }
   ],
   "source": [
    "output_annotations = liner2_xml_to_annotation(test_path) \n",
    "annotation_types = {annotation[0] for annotation in output_annotations}\n",
    "\n",
    "print(annotation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb08a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903478f-1c5d-470b-8897-c41ee8cf9145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0f9a9-0af3-492c-a0f7-6c731a9e6bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e21de5-e927-4493-87f0-dbdbe2d3c5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934f8cc-b063-40c1-bc9b-2aec68c28cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
