{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d95b42d-f8ed-41af-a21b-53fd5aa96256",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 3: data filtering and running NLP tasks\n",
    "\n",
    "In this exercise you will first learn how to use metadata properties for filtering data. We will then apply this to an example NLP pipeline.\n",
    "\n",
    "----\n",
    "Like in the previous exercise, we first need to install and 'import' some packages. Run the following cell to get everything in place. Notice that this is a cell that might take a bit more time to run. While `[*]` is shown next to a cell, this means that it is being processed or waiting to be processed and has not yet completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c51ea62-15a0-4df9-b095-029742393adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (4.8.0)\n",
      "Looking in indexes: https://pypi.clarin-pl.eu\n",
      "Requirement already satisfied: lpmn_client in /opt/conda/lib/python3.10/site-packages (1.4.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install -i https://pypi.clarin-pl.eu lpmn_client\n",
    "\n",
    "from lxml import etree\n",
    "from datetime import date\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Globals\n",
    "from common import align_resources, _check_task_size, data_dir, metadata_dir, nsmap, set_id, print_xml, output_file, unpack_metadata, unzip_file, zip_file\n",
    "# Getters\n",
    "from common import ex3_filter_by_date_and_content, get_date_from_metadata, get_resource_ids_from_metadata, get_resource_file, get_spellchecked_resources_ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a9151-6d39-42cf-95b7-aa02a680d1a9",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "\n",
    "For many research questions, we want to analyse one or more specific data segments based on some criteria. For this exercise we assume that we are interested to find names of persons, organisations, places etcetera found in texts mentioning the city of Kraków published in the first week of World War I.\n",
    "\n",
    "In the next cells, create the list of file paths of resources that meet these criteria:\n",
    "- publication date between 28 July 1914 and 4 August 1914\n",
    "- the resource file contains the text 'Kraków'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c3b33e8-c868-416f-84a1-e4011ddbe6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://europeana-oai.clarin.eu/metadata/fulltext-aggregation/9200357.zip\n",
      "Extracting content in /home/jovyan/temp/metadata/9200357\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/temp/metadata/9200357'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the metadata. We put this in its own cell so that we can run the filtering process separately\n",
    "set_metadata_dir = unpack_metadata(set_id, metadata_dir)\n",
    "\n",
    "set_metadata_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5902b50-27c6-4472-9145-c7ce8d789a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We provide two helper functions that gets all issue identifiers and the associated dates out of\n",
    "# a metadata record. You can use this as is.\n",
    "\n",
    "def get_issues_id_and_date(metadata_tree):\n",
    "    \"\"\"\n",
    "        Returns a list of tuples (id, date) for all issues in the metadata tree.\n",
    "        The 'date' part is a date object that supports retrieval of the date parts, i.e.\n",
    "        `date.year`, `date.month`, `date.day`\n",
    "    \"\"\"\n",
    "    issue_descriptions = metadata_tree.xpath('//cmdp_text:SubresourceDescription', namespaces=nsmap)\n",
    "    issues = [get_id_and_date_from_description(description) for description in issue_descriptions  if description is not None]\n",
    "    return [issue for issue in issues if issue is not None]\n",
    "\n",
    "def get_id_and_date_from_description(description_element):\n",
    "    \"\"\"\n",
    "        Helper that gets the identifier and date for a single issue. Returns None\n",
    "        if there is identifier and date information are not both present.\n",
    "    \"\"\"\n",
    "    issue_ids = description_element.findall('./cmdp_text:IdentificationInfo/cmdp_text:identifier', namespaces=nsmap)\n",
    "    issue_dates_start = description_element.find('./cmdp_text:TemporalCoverage/cmdp_text:Start/cmdp_text:date', namespaces=nsmap)\n",
    "    if len(issue_ids) > 0 and issue_dates_start is not None:\n",
    "        for issue_id in issue_ids:\n",
    "            if issue_id.text.isnumeric():\n",
    "                return (issue_id.text, date.fromisoformat(issue_dates_start.text))\n",
    "\n",
    "\n",
    "files = []\n",
    "for metadata_file in os.listdir(set_metadata_dir):\n",
    "    full_path = f'{set_metadata_dir}/{metadata_file}'\n",
    "    tree = etree.parse(full_path)\n",
    "    for info in get_issues_id_and_date(tree):\n",
    "        (issue_id, issue_date) = info\n",
    "        # We now have a numer identifier `issue_id` and a date `issue_date`\n",
    "        # from which we can get the year, month, day through `issue_date.year`,\n",
    "        # `issue_date.month`, `issue_date.day`. Use this to decide whether to include \n",
    "        # this issue.\n",
    "        \n",
    "        # If the date matches the desired range, we need to look at the resource itself\n",
    "        # to see if the target text appears.\n",
    "        # If you want, you can make use of the provided function get_resource_file(issue_id)\n",
    "        # to determine the path to the file.\n",
    "        #\n",
    "        # In Exercises set 2 we explored how to open a file and look for text inside\n",
    "        \n",
    "        # If both criteria match, we only need to add the file path to the array, which is\n",
    "        # done with `files.append(issue_id)`\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cefa6-f387-4f77-b3de-c5625141fc8f",
   "metadata": {},
   "source": [
    "In the next cell we compore the result to a predefined solution. In the following cells we will use the outcome of the predefined solution, so don't worry about moving on even if the outcomes do not fully match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce3560b-c5aa-478d-9d1f-35af18925b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in our own result: 0\n",
      "Number of files in result from predefined solution: 7\n",
      "The counts do not match :(\n"
     ]
    }
   ],
   "source": [
    "my_result = files\n",
    "print(f'Number of files in our own result: {len(my_result)}')\n",
    "\n",
    "# now we run the predefined solution\n",
    "predefined_result = ex3_filter_by_date_and_content(set_metadata_dir,\n",
    "                                       date.fromisoformat('1914-07-28'), \n",
    "                                       date.fromisoformat('1914-08-11'), 'w Polsce')\n",
    "print(f'Number of files in result from predefined solution: {len(predefined_result)}')\n",
    "\n",
    "if len(my_result) == len(predefined_result):\n",
    "    print('The counts match!')\n",
    "else:\n",
    "    print('The counts do not match :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6fa08-48bf-4ac7-a7f7-6b887aaf16e0",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "In this exercise we will try to investigate effect of using contemporary spellchecking on archival textual data. Due to the time required for spellchecking we provde a mapping to already processed files. Your job will be to run NER pipeline on raw and spell-corrected textual data and compare number of tokens and found annotations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f3e3dd-058d-4e78-a5a3-35b963bdbc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.clarin-pl.eu\n",
      "Requirement already satisfied: lpmn_client in /opt/conda/lib/python3.10/site-packages (1.4.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lpmn_client) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lpmn_client) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Email not provided - using default value. Please, visit https://gitlab.clarin-pl.eu/nlpworkers/lpmn_client for more information.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Install lpmn client and import it\n",
    "\"\"\"\n",
    "!pip install -i https://pypi.clarin-pl.eu lpmn_client\n",
    "\n",
    "from lpmn_client import download_file, upload_file\n",
    "from lpmn_client import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffd3a97-7539-491d-beda-5698e4d78828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function for tasking lpmn client with Liner2 NER pipeline with task size control \n",
    "\"\"\"\n",
    "\n",
    "def lpmn_client_task(resources, task, names=[]):\n",
    "    \"\"\"\n",
    "        Wrap over CLARIN-PL lpmn client with control of the task size in order to avoid jamming the task queue on the server side\n",
    "        \n",
    "        :param list resources: list of paths to the resources to be processed\n",
    "        :param str task: string defining pipeline, e.g. \"speller2\" or \"\"\n",
    "        :param list names: optional list of names for output files, has to be same length as resources\n",
    "        :returns list: list of paths to the output zip files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Size check\n",
    "    _check_task_size(resources)\n",
    "    # Upload reasources to task queue\n",
    "    job_ids = [upload_file(resource_file) for resource_file in resources]\n",
    "    # Specify pipeline \n",
    "    t = Task(task)\n",
    "    print(output_file)\n",
    "    # Run uploaded tasks with pipeline\n",
    "    output_file_ids = [t.run(job_id, verbose=True) for job_id in job_ids]\n",
    "\n",
    "    if names:\n",
    "        output = [download_file(output_file_id, output_file, f\"{os.path.basename(filename)}.zip\") \n",
    "                         for output_file_id, filename in zip(output_file_ids, names)]\n",
    "    else:\n",
    "        output = [download_file(output_file_id, output_file, f\"{os.path.basename(resource)}.zip\") \n",
    "                         for output_file_id, resource in zip(output_file_ids, resources)]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994cda7f-8736-4a37-aedb-ffc364648cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Get resources for the pipeline\n",
    "\"\"\"\n",
    "\n",
    "resource_files_raw = predefined_result\n",
    "\n",
    "# We already did for you, line below the comment, if running outside workshop, uncomment this comment block and comment the line below\n",
    "# resource_files_spellchecked = lpmn_client_task(resource_files, \"speller2\")\n",
    "# resource_files_spellchecked = [unzip_file(r) for r in resource_files_spellchecked]\n",
    "resource_files_spellchecked = get_spellchecked_resources_ex3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32b123a-a3c4-4fd4-aeda-ef9332e295d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100.0/100 [00:03<00:00, 33.21it/s]\n",
      "100%|██████████| 100.0/100 [00:05<00:00, 17.51it/s]\n",
      "100%|██████████| 100.0/100 [00:05<00:00, 17.43it/s]\n",
      "100%|██████████| 100.0/100 [00:05<00:00, 17.16it/s]\n",
      "100%|██████████| 100.0/100 [00:03<00:00, 32.72it/s]\n",
      "100%|██████████| 100.0/100 [00:05<00:00, 17.34it/s]\n",
      "100%|██████████| 100.0/100 [00:09<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER pipeline over raw resources finished\n",
      "/home/jovyan/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100.0/100 [00:08<00:00, 12.45it/s] \n",
      "100%|██████████| 100.0/100 [00:02<00:00, 34.74it/s]            \n",
      "100%|██████████| 100.0/100 [00:04<00:00, 22.98it/s]            \n",
      "100%|██████████| 100.0/100 [00:05<00:00, 18.36it/s]            \n",
      "100%|██████████| 100.0/100 [00:05<00:00, 19.88it/s]            \n",
      "100%|██████████| 100.0/100 [00:05<00:00, 19.84it/s]            \n",
      "100%|██████████| 100.0/100 [00:02<00:00, 44.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER pipeline over spellchecked resources finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Run NER task on both raw and spellchecked input, this may take a while\n",
    "\"\"\"\n",
    "output_files_raw = lpmn_client_task(resource_files_raw, \n",
    "                                    'any2txt|wcrft2|liner2({\"model\":\"top9\"})', \n",
    "                                    [f\"{os.path.basename(r)}_raw\" for r in resource_files_raw])\n",
    "output_files_raw = [f\"{o.replace('home%jovyan%data%9200357%', '')}\" for o in output_files_raw]\n",
    "print(\"NER pipeline over raw resources finished\")\n",
    "\n",
    "\n",
    "output_files_spellchecked = lpmn_client_task(resource_files_spellchecked, \n",
    "                                             'liner2({\"model\":\"top9\"})', \n",
    "                                             [f\"{os.path.basename(r)}_spellchecked\" for r in resource_files_spellchecked])\n",
    "output_files_spellchecked = [f\"{o.replace('home%jovyan%data%9200357%', '')}\" for o in output_files_spellchecked]\n",
    "print(\"NER pipeline over spellchecked resources finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c7ccca-8c27-4c96-8bbf-27fea52de70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack results and rename to avoid clashes from LPMN output\n",
    "\n",
    "output_files_raw = [f\"{unzip_file(o)[0]}\" for o in output_files_raw]\n",
    "for o in output_files_raw:\n",
    "    os.rename(o, f\"{o.replace('home%jovyan%data%9200357%', '')}_raw\")\n",
    "    \n",
    "output_files_spellchecked = [f\"{unzip_file(o)[0]}\" for o in output_files_spellchecked]\n",
    "for o in output_files_spellchecked:\n",
    "    os.rename(o, f\"{o.replace('home%jovyan%data%9200357%', '')}_spellchecked\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c30aff3-972e-4670-a10a-54a879b798eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files_raw = [f\"{o.replace('home%jovyan%data%9200357%', '')}_raw\" for o in output_files_raw]\n",
    "output_files_spellchecked = [f\"{o.replace('home%jovyan%data%9200357%', '')}_spellchecked\" for o in output_files_spellchecked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2139e7f6-3a2b-43fb-ac28-ef6096c23e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Functions for parsing output and basic stats\n",
    "\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_tokens(ner_output_tree):\n",
    "    return sum([1 for _ in ner_output_tree.xpath(\"//tok\")])\n",
    "\n",
    "def list_annotations(ner_output_tree):\n",
    "    return liner2_xml_to_annotation(ner_output_tree)\n",
    "\n",
    "def count_annotations(ner_output_tree) -> Counter:\n",
    "    return Counter(f\"{annotation_type}|{' '.join(annotation_tokens)}\" for annotation_type, annotation_tokens in list_annotations(ner_output_tree))\n",
    "\n",
    "def liner2_xml_to_annotation(ner_output_tree):\n",
    "    \"\"\"\n",
    "        Converts xml doc into list of annotations and tokens\n",
    "        \n",
    "        :param ElementTree ner_output_tree: lxml instance of ET of NER output xml\n",
    "        :returns list: list of tuples (annotation_type, [tokens])\n",
    "    \"\"\"\n",
    "    sentences = ner_output_tree.xpath(\"//sentence\")\n",
    "    annotated_tokens = [sentence.xpath(\"./tok[./ann!=0]\") for sentence in sentences]\n",
    "    # Prune empty lists\n",
    "    annotated_tokens = [annotated_token for annotated_token in annotated_tokens if annotated_token]\n",
    "    annotated_tokens = [_chain_annotations(sentence) for sentence in annotated_tokens]\n",
    "    return annotated_tokens\n",
    "        \n",
    "def _chain_annotations(sentence: list):\n",
    "    annotation_heads = [token.xpath(\"./ann[@head]\") for token in sentence]\n",
    "    for token in annotation_heads:\n",
    "        for annotation_head in token:\n",
    "            annotation_channel = annotation_head.xpath(\"./text()\")[0]\n",
    "            annotation_type = annotation_head.get(\"chan\")\n",
    "            annotation_tokens = [token.xpath(\"./lex/base/text()\")[0] for token in sentence if token.xpath(f\"./ann[text()={annotation_channel}]\")]\n",
    "    return annotation_type, annotation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7692ef11-0e3d-4e15-bd30-b84dfbfe271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/output/BibliographicResource_3000095242404/BibliographicResource_3000095242404.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243392/BibliographicResource_3000095243392.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095244058/BibliographicResource_3000095244058.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243952/BibliographicResource_3000095243952.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243514/BibliographicResource_3000095243514.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243250/BibliographicResource_3000095243250.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095236729/BibliographicResource_3000095236729.txt_raw\n",
      "Raw data has 145234 tokens\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095236729/BibliographicResource_3000095236729.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095242404/BibliographicResource_3000095242404.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243250/BibliographicResource_3000095243250.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243952/BibliographicResource_3000095243952.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095244058/BibliographicResource_3000095244058.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243392/BibliographicResource_3000095243392.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243514/BibliographicResource_3000095243514.txt_spellchecked\n",
      "Spellchecked data has 145234 tokens\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Let's invastigate difference in number of parsed tokens in raw and spellchecked data\n",
    "\"\"\"\n",
    "\n",
    "# Raw\n",
    "token_nb_raw = 0\n",
    "for o in output_files_raw:\n",
    "    print(f\"Processing {o}\")\n",
    "    xml_tree = etree.parse(o)\n",
    "    token_nb_raw += count_tokens(xml_tree)\n",
    "print(f\"Raw data has {token_nb_raw} tokens\")\n",
    "\n",
    "# Spellchecked\n",
    "token_nb_spellchecked = 0\n",
    "for o in output_files_spellchecked:\n",
    "    print(f\"Processing {o}\")\n",
    "    xml_tree = etree.parse(o)\n",
    "    token_nb_spellchecked += count_tokens(xml_tree)\n",
    "print(f\"Spellchecked data has {token_nb_spellchecked} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f356bb67-42d2-486c-855a-8b49e9f7b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/output/BibliographicResource_3000095242404/BibliographicResource_3000095242404.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243392/BibliographicResource_3000095243392.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095244058/BibliographicResource_3000095244058.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243952/BibliographicResource_3000095243952.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243514/BibliographicResource_3000095243514.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243250/BibliographicResource_3000095243250.txt_raw\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095236729/BibliographicResource_3000095236729.txt_raw\n",
      "Raw data annotations: [('nam_loc|Warszawa', 40), ('nam_loc|Niemcy', 35), ('nam_loc|Serbia', 31), ('nam_loc|Berlin', 31), ('nam_loc|Lew', 31), ('nam_loc|Rosja', 29), ('nam_loc|Londyn', 21), ('nam_loc|Francja', 20), ('nam_loc|Wiedeń', 18), ('nam_loc|Polska', 18)]\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095236729/BibliographicResource_3000095236729.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095242404/BibliographicResource_3000095242404.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243250/BibliographicResource_3000095243250.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243952/BibliographicResource_3000095243952.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095244058/BibliographicResource_3000095244058.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243392/BibliographicResource_3000095243392.txt_spellchecked\n",
      "Processing /home/jovyan/output/BibliographicResource_3000095243514/BibliographicResource_3000095243514.txt_spellchecked\n",
      "Spellchecked data annotations: [('nam_loc|Warszawa', 38), ('nam_loc|Niemcy', 34), ('nam_loc|Lew', 31), ('nam_loc|Berlin', 30), ('nam_loc|Serbia', 28), ('nam_loc|Rosja', 28), ('nam_loc|Francja', 19), ('nam_loc|Londyn', 19), ('nam_loc|Polska', 18), ('nam_loc|Wiedeń', 18)] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Let's check how annotation counts differ on entire output\n",
    "\"\"\"\n",
    "# Raw\n",
    "annotation_nb_raw = Counter()\n",
    "for o in output_files_raw:\n",
    "    print(f\"Processing {o}\")\n",
    "    xml_tree = etree.parse(o)\n",
    "    annotation_nb_raw += count_annotations(xml_tree)\n",
    "print(f\"Raw data annotations: {annotation_nb_raw.most_common(10)}\")\n",
    "\n",
    "# Spellchecked\n",
    "annotation_nb_spellchecked = Counter()\n",
    "for o in output_files_spellchecked:\n",
    "    print(f\"Processing {o}\")\n",
    "    xml_tree = etree.parse(o)\n",
    "    annotation_nb_spellchecked += count_annotations(xml_tree)\n",
    "print(f\"Spellchecked data annotations: {annotation_nb_spellchecked.most_common(10)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c985b5-6126-4df9-b3a6-e5066a2938c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Now, your job is to investigate how annotations number differs per file \n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "def align_resources(resources_raw, resources_spelled):\n",
    "    ret = []\n",
    "    for rraw in resources_raw:\n",
    "        for rspelled in resources_spelled:\n",
    "            if os.path.basename(rraw).split(\".\")[0] == os.path.basename(rspelled).split(\".\")[0]:\n",
    "                ret.append((rraw, rspelled))\n",
    "    return ret\n",
    "aligned_resources = align_resources(output_files_raw, output_files_spellchecked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dc21aec-6ab4-4c7d-90fd-a92f0a9cb28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 7 (896498286.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [18]\u001b[0;36m\u001b[0m\n\u001b[0;31m    fig = plt.figure()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Fill in for loop body\n",
    "\"\"\"\n",
    "\n",
    "diff_counts: List[int] = []\n",
    "\n",
    "for rraw, rspelled in aligned_resources:\n",
    "    # Sum all differences in number of annotation occurences. Note that \n",
    "    # a) you can use `+` and `-` on Counter instance\n",
    "    # b) Counter instance does not store negative values (<0 are discarded from dict), \n",
    "    #    you can try: \n",
    "    #        diff_in_occur = sum(((counterA - counterB) + (counterB - counterA)).values())\n",
    "    \n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "resource_names = [os.path.basename(rraw).replace(\"_raw\", \"\") for rraw, _ in aligned_resources]\n",
    "plt.xticks(rotation=90)\n",
    "ax.bar(resource_names, diff_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11a80eb-b107-453e-96b8-b7ae65673723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100.0/100 [01:12<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/output/BibliographicResource_3000095242404.txt_n82.zip']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    SANDBOX\n",
    "    \n",
    "    Congratulations, you have finished our tutorial. Liner2 models come with different level of granularity of annotations. \n",
    "    Here, we invite you to investigate n82, that introduces additional level of granularity to annatations we presented \n",
    "    in previous sections\n",
    "\"\"\"\n",
    "predefined_resource = predefined_result[0]\n",
    "\n",
    "lpmn_client_task([predefined_resource], 'any2txt|wcrft2|liner2({\"model\":\"n82\"})', [f\"{predefined_resource}_n82\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee6be2-5f0e-40c8-a5fb-06fa19757402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8f9d7-c8d5-4da3-ad8c-73da54ddedd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b2699-dc15-4162-9c66-82c611c6a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
